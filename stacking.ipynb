{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mvideo hackathon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import canonicals\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import keras\n",
    "\n",
    "import xgboost \n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import  RandomForestClassifier, AdaBoostClassifier, ExtraTreesClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (10, 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Считаем данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('X_train.csv',)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выбирем только нужные нам поля"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = data[['comment', 'commentPositive', 'commentNegative', 'reting']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Исследование данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выведем несколько отзывов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def display(idx):\n",
    "    print('Text: ', data.loc[idx].comment)\n",
    "    if not pd.isnull(data.loc[idx].commentPositive):\n",
    "        print('Positive: ', data.loc[idx].commentPositive)\n",
    "        print('Negative: ', data.loc[idx].commentNegative)\n",
    "    print('Rating: ', data.loc[idx].reting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text:  Я считаю, что цена не оправдывает то качество, что предоставляет модель.  скорость памяти 4Гб, но кэш всего 1мб.- это очень слабо. Видеокарта более менее, но опять-таки, из-за слабой оперативки, видеокарта сожрёт всю память. Ну и конечно же батарея 2.5 часа - это просто ни к чему придраться, с чего батарея так быстро садиться?! Ноутбук не такой уж и мощный! Моя оценка 3 из 5.(по доброте к м.видео)\n",
      "Rating:  3.0\n"
     ]
    }
   ],
   "source": [
    "display(150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text:  Красивый дизайн, удобное меню.\n",
      "Positive:  «Эксперт месяца»  Во-первых хочу сказать, что очень довольна данной покупкой, несмотря на довольно высокую цену товара. Очень нравится, что перед первым применением  аппарат попросил установить уровень жесткости воды.  Кстати очень хорошо, что в комплекте есть индикатор жесткости воды, просто чудо! Сразу после установки данной настройки можно изменить время автоматического отключения кофемашины, которое при заводских настройках составляет два часа.   В комплект также входит  фильтр для смягчения воды. Когда он закончится, можно использовать обычные фильтры, например Аквафор. Также машина сообщает о необходимости декальцификации. Неплохое  средство EcoDecalk от того же бренда, что и сама кофемашина. Стоит 1000, хватает на пять применений, то есть где-то на пять лет хватит.  Кофемашина варит эспрессо, двойной эспрессо, каппучино и латте.   Крепость кофе можно регулировать круглым рычажком  на передней панели.   Кофе очень вкусный, только кофемолка шумит громко.  Кофемашина сама уведомляет хозяина о своих потребностях (например почистить).  При приготовлении кофе можно использовать не только цельные зерна, но и молотый кофе.  Кофемашина позволяет взбивать молоко для каппучино с помощью пара, что я очень люблю делать.  Советы от меня, как хорошо взбить молоко:  1 Вам понадобится натуральное молоко, которое следует предварительно подержать в холодильнике.  2 Наполните холдер молотым кофе и установите его в приемник. Убедитесь, что отсек для воды наполнен и включите нагрев.   3 Включите режим подачи пара и подождите несколько секунд, пока пар не станет сухим, без брызг конденсата, собравшегося внутри трубки. Если пренебречь этим этапом, капли воды будут охлаждать пену и не дадут как следует взбить молоко для капучино.  4 Налейте в питчер или высокую чашку столько молока, чтобы хватило для приготовления кофе, но чтобы до края питчера оставалось не меньше половины его высоты. При взбивании молоко увеличится в объеме, и свободное место нужно предусмотреть заранее.  5 Опустите капучинатор в молоко, погрузив трубку и не доставая до дня питчера около 2 см. держите емкость так, чтобы трубка располагалась не строго по центру, а немного ближе к одной из стенок.  6 Включите подачу пара и немного перемещайте емкость с молоком вращательными движениями в одну и другую сторону. Вы увидите, как пар взбивает молоко и образует пышную пену на границе воздуха и жидкости.  7 Когда пена станет однородной и «гладкой», выключите парогенератор.     Пенка из молока, правильно взбитого капучинатором, получается устойчивой и плотной, поэтому позволяет украсить капучино тертым шоколадом, корицей или порошком какао.   Надеюсь, мой отзыв поможет сделать вам правильный выбор, а я со спокойной душой могу советовать эту модель кофемашины.\n",
      "Negative:  Шумные кофемолки, черный цвет очень маркий.\n",
      "Rating:  5.0\n"
     ]
    }
   ],
   "source": [
    "display(1132)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text:  вообще часто серия ноут буков и компьютером Acer очень плохая, не знаю в чем тут дело но греется и лагает большинство компов этого производителя, если увидите на компьютере надпись Acer просто проходите мимо не делайте такой ошибки как сделал я!!!\n",
      "Rating:  1.0\n"
     ]
    }
   ],
   "source": [
    "display(133)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Процент отзывов с указанными позитивными и негативными сторонами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.92160133445 %\n"
     ]
    }
   ],
   "source": [
    "print(sum(~pd.isnull(data['commentPositive'])) / data.shape[0] * 100, '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как мы видим, очень малое число людей указывает что-то в этих полях, поэтому чтобы достать из них хоть что-то, соеденим их в один текст с отзывом. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Распределение рейтингов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fcff2ce5358>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmAAAAGlCAYAAABdpkpKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAADjBBgAwDABBgAwTIABAAwTYAAAw/4/Rp2LKRU0x90AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fcff1dd4320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data.reting.value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как мы видим, большинство рейтингов представляют из себя целые числа между 1 и 5. Неполные числа можно просто округлить, сведя таким образом задачу к классификации на пять классов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так же классы крайне несбалансированы, поэтому лучше всего использовать веса классов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Подготовка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Длинная строка кода для соединения отзывов с комментариями"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "texts = data.comment + ' ' + data.commentPositive.apply(lambda x:'' if str(x) == 'nan' else str(x)) + ' ' + data.commentNegative.apply(lambda x:'' if str(x) == 'nan' else str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "texts = texts.rename('texts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.concat([texts, data.reting], axis=1,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Рейтинги"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Округляем до ближайшего целого числа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['reting'] = data.reting.apply(round)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Стоп слова для фильтрации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Эти слова можно спокойно выкинуть из теста, так как они не несут никакой полезной информации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('russian')\n",
    "stop_words.extend(['что', 'это', 'так', 'вот', 'быть', 'как', 'в', '—', 'к', 'на'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Лемматизация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сделаем лемматизацию, чтобы при векторизации учитывать только смысловую окраску слов, а не их синтаксическую форму."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lemmatize_function = lambda text: ' '.join(canonicals.text2canonicals(text, stop_words=stop_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['lemmas'] = data.texts.apply(lemmatize_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learning. Не пропустите! Вы не поверите, что сделала вторая модель..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Чистый TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tf-IDF - метод векторизации текстов, который может учитывать не только количество раз, которое оно встретилось в тексте, но и в скольких других оно встречалось."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таким образом, он присваевает большие веса тем словам, которые часто втречаются в этом тексте и в малом количестве других текстов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CSCMaker(object):\n",
    "    '''\n",
    "    Этот класс нужен, чтобы переводить csr матрицу, возвращемую векторизатором в csc.\n",
    "    Так как XGBoost по какой-то причине может работать только с ними.\n",
    "    '''\n",
    "    def fit(self, X, y=None):\n",
    "        pass\n",
    "    \n",
    "    def fit_transform(self, X, y=None):\n",
    "        return self.transform(X)\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        return X.tocsc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "cscmaker = CSCMaker()\n",
    "\n",
    "model = xgboost.XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipe = Pipeline([('vectorizer', tfidf), ('csc', cscmaker), ('model', model)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.57255430736194668"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cross_val_score(pipe, data.lemmas, data.reting, scoring='f1_weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ModelStacking:\n",
    "    def __init__(self, first_level, second_level):\n",
    "        '''\n",
    "        first_level: список моделей первого уровня\n",
    "        second_level: self explainatory...\n",
    "        '''\n",
    "        self.first_level = first_level\n",
    "        self.second_level = second_level\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \n",
    "        first_level_features = []\n",
    "        \n",
    "        for model in self.first_level:\n",
    "            model.fit(X, y)\n",
    "            first_level_features.append(model.predict_proba(X))\n",
    "        \n",
    "        self.second_level.fit(np.concatenate(first_level_features, axis=1), y)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \n",
    "        features = np.concatenate(list(map(lambda x: x.predict_proba(X), self.first_level)), axis=1)\n",
    "        \n",
    "        return self.second_level.predict(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf_params = {\n",
    "    'n_jobs': -1,\n",
    "    'n_estimators': 500,\n",
    "     'warm_start': True, \n",
    "    'max_depth': 6,\n",
    "    'min_samples_leaf': 2,\n",
    "    'max_features' : 'sqrt',\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "# Extra Trees Parameters\n",
    "et_params = {\n",
    "    'n_jobs': -1,\n",
    "    'n_estimators':500,\n",
    "    'max_depth': 8,\n",
    "    'min_samples_leaf': 2,\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "# AdaBoost parameters\n",
    "ada_params = {\n",
    "    'n_estimators': 500,\n",
    "    'learning_rate' : 0.75\n",
    "}\n",
    "\n",
    "# Gradient Boosting parameters\n",
    "gb_params = {\n",
    "    'n_estimators': 500,\n",
    "    'max_depth': 5,\n",
    "    'min_samples_leaf': 2,\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "# Support Vector Classifier parameters \n",
    "svc_params = {\n",
    "    'kernel' : 'linear',\n",
    "    'C' : 0.025,\n",
    "    'probability': True\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "first_level = [\n",
    "    RandomForestClassifier(**rf_params),\n",
    "    ExtraTreesClassifier(**et_params),\n",
    "    AdaBoostClassifier(**ada_params),\n",
    "    LogisticRegression(),\n",
    "    SVC(**svc_params)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "second_level = xgboost.XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stack = ModelStacking(first_level, second_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipe = Pipeline([('vectorizer', tfidf), ('model', stack)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.61024513034987926"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cross_val_score(pipe, data.lemmas, data.reting, scoring='f1_weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.60255296206479503"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cross_val_score(pipe, data.lemmas, data.reting, scoring='accuracy'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## W2V Подход"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь немного другой подход"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возьмем эмбеддинги (векторное представления слова, полученное из модели [skipgram](http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/) всех слов одного предложения, а затем усредним, получив таким образом вектор предлжения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def has_key(key, dict_):\n",
    "    try:\n",
    "        dict_[key]\n",
    "        return True\n",
    "    except:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class WordVectorizer:\n",
    "    \n",
    "    def __init__(self, model_path):\n",
    "        self.vecs = KeyedVectors.load(model_path)\n",
    "    \n",
    "    def translate_sentence(self, sentence):\n",
    "        return np.array(list(map(lambda x: self.vecs[x], filter(lambda x: has_key(x, self.vecs), sentence.split()))))\n",
    "    \n",
    "    def get_sentence_vec(self, sent_vecs):\n",
    "        return np.mean(sent_vecs, axis=0)\n",
    "    \n",
    "    def fit(self, data, y=None):\n",
    "        return\n",
    "    \n",
    "    def transform(self, data):\n",
    "        return np.array(list(map(lambda x: self.get_sentence_vec(self.translate_sentence(x)), data)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = WordVectorizer('ru.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ready_words = data.texts.apply(lambda x: ' '.join(filter(lambda x: has_key(x, vectorizer.vecs), canonicals.getWords(x, stop_words))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['vector_ready'] = ready_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Есть пара отзывов, в которых после удаления слов без соответсвующих векторов остались пусты. Их можно легко выкинуть, вряд ли кто-то обидится."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filter_index = [len(x)!=0 for x in ready_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sent_vecs = vectorizer.transform(data.loc[filter_index].vector_ready)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = xgboost.XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48206871456809292"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cross_val_score(model, sent_vecs, data.loc[filter_index].reting, scoring='f1_weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Улучшенный W2V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пришла пора эзотерический методов. Умножаем вектора на соотетсвующие значения TF-IDF и надеемся на лучшее."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_vecs = list(map(vectorizer.translate_sentence, data.vector_ready.loc[filter_index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_tfidf_values(sent, vec, vocab):\n",
    "    raw_vec = vec.toarray()[0]\n",
    "    return np.array(list(map(lambda x: raw_vec[vocab[x]], sent.split())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['vec_lem'] = data.vector_ready.apply(lemmatize_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocabulary = np.unique(' '.join(data.vec_lem).strip(' ').split(' ')) # это необходимо так как без заданного \n",
    "                                        # vocabulary векторизатор выкидывает слвоа,длиной в одну букву "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(vocabulary=vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_tf_idfs = tfidf.fit_transform(data.loc[filter_index].vec_lem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf_idfs = list(map(lambda x: get_tfidf_values(x[0], x[1], tfidf.vocabulary_), zip(data.loc[filter_index].vec_lem, raw_tf_idfs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_vecs = np.array(list(map(lambda x: np.mean((x[0].T * x[1]).T, axis=0), zip(word_vecs, tf_idfs))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=80, class_weight='balanced', max_features=0.5, n_jobs=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = xgboost.XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47499869282026586"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cross_val_score(model, data_vecs, data.loc[filter_index].reting, scoring='f1_weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Итог"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "Ну что же, мы протестировли ряд моделей, некоторый из них были достаточно большими нейронками и тем не менее точность не поднималась выше 62~63%, а самая высокая F мера - 0.58. "
=======
    "Ну что же, мы протестировли ряд моделей, некоторый из них были достаточно большими нейронками и тем не менее точность не поднималась выше 62~63%, а самая высокая F - 0.58. "
>>>>>>> e1307ba47387eedd5d561e2d7dda00a8a3a0b615
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как-то так, надеемся вам понравилось :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Тестовые данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv('X_final_test.csv')[['comment', 'commentPositive', 'commentNegative']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = test.comment + ' ' + test.commentPositive.apply(lambda x:'' if str(x) == 'nan' else str(x)) + ' ' + test.commentNegative.apply(lambda x:'' if str(x) == 'nan' else str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_lems = test.apply(lemmatize_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipe = Pipeline([('vectorizer', tfidf), ('csc', cscmaker), ('model', xgboost.XGBClassifier())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vectorizer', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=Tr...softprob', reg_alpha=0, reg_lambda=1,\n",
       "       scale_pos_weight=1, seed=0, silent=True, subsample=1))])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit(data.lemmas, data.reting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = pipe.predict(test_lems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv('X_final_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test['rating'] = pd.Series(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test.to_csv('old_pred.csv')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
